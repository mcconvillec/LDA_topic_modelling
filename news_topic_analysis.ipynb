{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation\n",
    "\n",
    "LDA is an unsupervised classification methods used to classify different text documents into a particular topics. Classifications are based on definining word-topic relationships using Dirichlet distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gensim\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "import nltk\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_sci_lg  # model downloaded in previous step\n",
    "nlp = spacy.load(\"en_core_web_sm\")    ### Load spacy NLP processor\n",
    "#nltk.download('wordnet')\n",
    "np.random.seed(400)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this example is the 20newsgroup dataset available from sklearn. This dataset has news articles grouped into 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle = True)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "The following steps will be performed in order to clean raw text and reduce the sparsity of the dataset:\n",
    "- Tokenization: split text into words, convert to lowercase and remove punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatize words: removes inflection endings of words to obtain base/dictionary form of the word (e.g. am, are, is $\\Rightarrow$ be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    \"\"\"\n",
    "    Function accepts raw text string and performs tokenization, removes punctuation and lemmitizers words. Only tokens\n",
    "    with length greater than 3 are kept.\n",
    "    \n",
    "    Returns list of tokens\n",
    "    \"\"\"\n",
    "    processed_text = []\n",
    "    for token in gensim.utils.simple_preprocess(txt):\n",
    "        #Remove stopwords or small tokens\n",
    "        if token not in STOP_WORDS and len(token) > 3:\n",
    "            processed_text.append(WordNetLemmatizer().lemmatize(token, pos = 'v'))\n",
    "            \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "['From:', 'johnc@crsa.bu.edu', '(John', 'Collins)\\nSubject:', 'Problem', 'with', 'MIT-SHM\\nOrganization:', 'Boston', 'University\\nLines:', '27\\n\\nI', 'am', 'trying', 'to', 'write', 'an', 'image', 'display', 'program', 'that', 'uses\\nthe', 'MIT', 'shared', 'memory', 'extension.', '', 'The', 'shared', 'memory', 'segment\\ngets', 'allocated', 'and', 'attached', 'to', 'the', 'process', 'with', 'no', 'problem.\\nBut', 'the', 'program', 'crashes', 'at', 'the', 'first', 'call', 'to', 'XShmPutImage,\\nwith', 'the', 'following', 'message:\\n\\nX', 'Error', 'of', 'failed', 'request:', '', 'BadShmSeg', '(invalid', 'shared', 'segment', 'parameter)\\n', '', 'Major', 'opcode', 'of', 'failed', 'request:', '', '133', '(MIT-SHM)\\n', '', 'Minor', 'opcode', 'of', 'failed', 'request:', '', '3', '(X_ShmPutImage)\\n', '', 'Segment', 'id', 'in', 'failed', 'request', '0x0\\n', '', 'Serial', 'number', 'of', 'failed', 'request:', '', '741\\n', '', 'Current', 'serial', 'number', 'in', 'output', 'stream:', '', '742\\n\\nLike', 'I', 'said,', 'I', 'did', 'error', 'checking', 'on', 'all', 'the', 'calls', 'to', 'shmget\\nand', 'shmat', 'that', 'are', 'necessary', 'to', 'create', 'the', 'shared', 'memory\\nsegment,', 'as', 'well', 'as', 'checking', 'XShmAttach.', '', 'There', 'are', 'no\\nproblems.\\n\\nIf', 'anybody', 'has', 'had', 'the', 'same', 'problem', 'or', 'has', 'used', 'MIT-SHM', 'without\\nhaving', 'the', 'same', 'problem,', 'please', 'let', 'me', 'know.\\n\\nBy', 'the', 'way,', 'I', 'am', 'running', 'OpenWindows', '3.0', 'on', 'a', 'Sun', 'Sparc2.\\n\\nThanks', 'in', 'advance--\\nJohn', 'C.\\n\\n\\n']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['johnc', 'crsa', 'john', 'collins', 'subject', 'problem', 'organization', 'boston', 'university', 'line', 'try', 'write', 'image', 'display', 'program', 'use', 'share', 'memory', 'extension', 'share', 'memory', 'segment', 'get', 'allocate', 'attach', 'process', 'problem', 'program', 'crash', 'xshmputimage', 'follow', 'message', 'error', 'fail', 'request', 'badshmseg', 'invalid', 'share', 'segment', 'parameter', 'major', 'opcode', 'fail', 'request', 'minor', 'opcode', 'fail', 'request', 'x_shmputimage', 'segment', 'fail', 'request', 'serial', 'number', 'fail', 'request', 'current', 'serial', 'number', 'output', 'stream', 'like', 'say', 'error', 'check', 'call', 'shmget', 'shmat', 'necessary', 'create', 'share', 'memory', 'segment', 'check', 'xshmattach', 'problems', 'anybody', 'problem', 'have', 'problem', 'know', 'run', 'openwindows', 'sparc', 'thank', 'advance', 'john']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Example of preprocessing workflow\n",
    "'''\n",
    "document_num = 50\n",
    "doc_sample = newsgroups_train.data[document_num]\n",
    "\n",
    "print(\"Original document: \")\n",
    "print(doc_sample.split(' '))\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(clean_txt(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess all documents in data\n",
    "processed_documents_train = []\n",
    "processed_documents_test = []\n",
    "\n",
    "for train_doc, test_doc in zip(newsgroups_train.data, newsgroups_test.data):\n",
    "    processed_documents_train.append(clean_txt(train_doc))\n",
    "    processed_documents_test.append(clean_txt(test_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert documents to Bag of Words representation\n",
    "\n",
    "BoW representation results in displaying each document as a count of the number of times each unique word appears in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_dictionary = gensim.corpora.Dictionary(processed_documents)\n",
    "\n",
    "\"\"\"\n",
    "Filter out\n",
    "- Words occurring infrequently (less than or equal to 10)\n",
    "- Words occurring in more than 80% of all documents\n",
    "\"\"\"\n",
    "\n",
    "bow_dictionary.filter_extremes(no_below=10, no_above=0.8)\n",
    "\n",
    "#Convert to BoW\n",
    "train_bow_corpus = [bow_dictionary.doc2bow(doc) for doc in processed_documents_train]\n",
    "test_bow_corpus = [bow_dictionary.doc2bow(doc) for doc in processed_documents_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 13 (\"info\") has a score of 2 \n",
      "Word 14 (\"know\") has a score of 1 \n",
      "Word 16 (\"look\") has a score of 2 \n",
      "Word 23 (\"post\") has a score of 1 \n",
      "Word 30 (\"thank\") has a score of 1 \n",
      "Word 32 (\"university\") has a score of 1 \n",
      "Word 33 (\"wonder\") has a score of 1 \n",
      "Word 37 (\"answer\") has a score of 1 \n",
      "Word 48 (\"disk\") has a score of 2 \n",
      "Word 56 (\"haven\") has a score of 1 \n"
     ]
    }
   ],
   "source": [
    "# Example document\n",
    "example = train_bow_corpus[2]\n",
    "\n",
    "#Show 10 words\n",
    "for i in range(10):\n",
    "    print(\"Word {} (\\\"{}\\\") has a score of {} \".format(example[i][0],\\\n",
    "         bow_dictionary[example[i][0]], example[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the LDA\n",
    "\n",
    "The parameters that will be adjusted in this model will be:\n",
    "\n",
    "- <b>num_topics</b>: The number of latent topics to be extracted across all documents. We will define this as 10 upfront\n",
    "- <b>alpha</b> and <b>eta</b>: define the sparsity of the document-topic (eta) and topic-word (lambda) distributions. Higher values indicate that each document/word comprises a mixture of a broader set of topics/words versus lower values which indicate that each document/word is defined by a smaller subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train LDA model\n",
    "\n",
    "lda_model =  gensim.models.LdaMulticore(train_bow_corpus, \n",
    "                                   num_topics = 8, \n",
    "                                   id2word = bow_dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.011*\"file\" + 0.009*\"windows\" + 0.008*\"program\" + 0.007*\"write\" + 0.007*\"drive\" + 0.007*\"image\" + 0.006*\"post\" + 0.006*\"work\" + 0.006*\"system\" + 0.005*\"card\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.010*\"space\" + 0.008*\"write\" + 0.007*\"nasa\" + 0.007*\"article\" + 0.006*\"post\" + 0.005*\"nntp\" + 0.005*\"host\" + 0.004*\"work\" + 0.004*\"university\" + 0.004*\"program\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.011*\"people\" + 0.008*\"think\" + 0.008*\"write\" + 0.006*\"know\" + 0.006*\"say\" + 0.006*\"believe\" + 0.005*\"article\" + 0.005*\"time\" + 0.005*\"mean\" + 0.004*\"right\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.010*\"file\" + 0.007*\"information\" + 0.007*\"encryption\" + 0.005*\"program\" + 0.005*\"post\" + 0.005*\"chip\" + 0.005*\"privacy\" + 0.005*\"number\" + 0.004*\"output\" + 0.004*\"security\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.013*\"post\" + 0.012*\"write\" + 0.011*\"article\" + 0.010*\"nntp\" + 0.010*\"host\" + 0.009*\"university\" + 0.007*\"like\" + 0.006*\"distribution\" + 0.006*\"know\" + 0.005*\"think\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.008*\"people\" + 0.008*\"israel\" + 0.008*\"scsi\" + 0.007*\"armenian\" + 0.007*\"turkish\" + 0.007*\"write\" + 0.007*\"israeli\" + 0.006*\"armenians\" + 0.006*\"say\" + 0.006*\"jews\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.011*\"game\" + 0.009*\"team\" + 0.008*\"play\" + 0.008*\"think\" + 0.008*\"write\" + 0.007*\"go\" + 0.007*\"say\" + 0.007*\"know\" + 0.006*\"come\" + 0.006*\"university\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.010*\"write\" + 0.008*\"article\" + 0.007*\"like\" + 0.007*\"know\" + 0.007*\"time\" + 0.006*\"go\" + 0.006*\"think\" + 0.006*\"post\" + 0.005*\"people\" + 0.005*\"right\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show words and weightings by topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic inference\n",
    "\n",
    "Based on the topic groupings and relative weightings of component words. The 8 topics can be infered:\n",
    "\n",
    "- 0: Technology (graphics)\n",
    "- 1: Space\n",
    "- 2: Religion\n",
    "- 3: Encryption\n",
    "- 4: Education\n",
    "- 5: Middle East\n",
    "- 6: Sport\n",
    "- 7: Opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify unseen document from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jussi@tor.abo.fi (Jussi Laaksonen DC)\n",
      "Subject: Lasergraphics Language ?\n",
      "Organization: ]bo Akademi University, Finland\n",
      "Distribution: comp.graphics\n",
      "Lines: 25\n",
      "\n",
      "Hi!\n",
      "\n",
      "We have an old Montage FR-1 35mm film recorder. When connected to a PC with\n",
      "its processor card it can directly take HPGL, Targa and Lasergraphics Language\n",
      "files. 24 bit Targa is quite OK for raster images, but conversion from \n",
      "whatever one happens to have can be quite slow. This Lasergraphics Language\n",
      "seems to be (got the source file for one test image) a vector-based language\n",
      "that can handle one million colors. It does some polygons too, and perhaps\n",
      "something else ?\n",
      "\n",
      "The question is, where can I find some information about this language ?\n",
      "A FTP site, a book, a company address,.... ?\n",
      "\n",
      "(OK, it would be nice to have a Windows driver for it, but I'm not THAT\n",
      "optimistic...)\n",
      "\n",
      "Thanks in advance for any help!\n",
      "\n",
      "\tjussi\n",
      "\n",
      "\n",
      "--\n",
      "\tJussi Laaksonen\n",
      "        Computing Centre / ]bo Akademi University,  Finland\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_index = random.randint(0, len(test_bow_corpus) - 1)\n",
    "bow_doc = test_bow_corpus[sample_index]\n",
    "print(newsgroups_test.data[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.98\t Topic: 0.011*\"file\" + 0.009*\"windows\" + 0.008*\"program\" + 0.007*\"write\" + 0.007*\"drive\"\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing step for the unseen document\n",
    "for index, score in sorted(lda_model[bow_doc], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {:.2f}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of topics in test set\n",
    "possible_outcomes=list(newsgroups_test.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "#Actual label of test case\n",
    "print(possible_outcomes[newsgroups_test.target[sample_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly classifies the document as technology (graphics) with 98% probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
